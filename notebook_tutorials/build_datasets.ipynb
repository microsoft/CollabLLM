{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CollabLLM Dataset Construction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two types of datasets in CollabLLM:\n",
    "- SingTurnDataset: Any single-turn tasks can be defined as a SingTurnDataset.\n",
    "- MultiTurnDataset: Any multiturn conversation can be stored as MultiTurnDataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-turn dataset\n",
    "\n",
    "Demonstrates:\n",
    "1. Creating a list of single-turn chat entries.\n",
    "2. Wrapping it with SingTurnDataset.\n",
    "3. Converting to a HuggingFace DatasetDict.\n",
    "4. Inspecting splits and sample entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 14:03:12,935 [INFO] collabllm: CollabLLM logging enabled.\n",
      "2025-06-13 14:03:13,801 [INFO] httpx: HTTP Request: GET https://raw.githubusercontent.com/BerriAI/litellm/main/model_prices_and_context_window.json \"HTTP/1.1 200 OK\"\n",
      "2025-06-13 14:03:15,259 [INFO] collabllm: Disable LiteLLM cache and logging by default. \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/dfs/project/kgrlm/github/collabllm\") \n",
    "from pprint import pprint\n",
    "from datasets import DatasetDict\n",
    "from collabllm.datasets import SingleTurnDataset\n",
    "\n",
    "# ------------------------------------------------------ #\n",
    "# 1) Prepare some toy single-turn data                   #\n",
    "# ------------------------------------------------------ #\n",
    "toy_data = [\n",
    "    {\n",
    "        \"prompt\": \"What is the capital of France?\",\n",
    "        \"completion\": \"Paris.\",\n",
    "        \"difficulty\": \"easy\",\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"Compute 15 * 7.\",\n",
    "        \"completion\": \"105.\",\n",
    "        \"difficulty\": \"easy\",\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"Explain the theory of relativity in brief.\",\n",
    "        \"completion\": \"It’s a theory by Einstein explaining how space and time are linked and how massive objects curve spacetime. In short, E=mc².\",\n",
    "        \"difficulty\": \"hard\",\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"Who wrote 'Pride and Prejudice'?\",\n",
    "        \"completion\": \"Jane Austen.\",\n",
    "        \"difficulty\": \"medium\",\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"Translate 'Hello' to Spanish.\",\n",
    "        \"completion\": \"Hola.\",\n",
    "        \"difficulty\": \"easy\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------ #\n",
    "# 2) Initialize SingleTurnDataset                          #\n",
    "# ------------------------------------------------------ #\n",
    "dataset = SingleTurnDataset(toy_data, eval_ratio=0.2, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splits: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['single_turn_prompt', 'single_turn_completion', 'single_turn_metadata'],\n",
      "        num_rows: 4\n",
      "    })\n",
      "    eval: Dataset({\n",
      "        features: ['single_turn_prompt', 'single_turn_completion', 'single_turn_metadata'],\n",
      "        num_rows: 1\n",
      "    })\n",
      "})\n",
      "Split info: {'train': 4, 'eval': 1}\n",
      "\n",
      "--- TRAIN split ---\n",
      "{'single_turn_completion': '105.',\n",
      " 'single_turn_metadata': {'difficulty': 'easy'},\n",
      " 'single_turn_prompt': 'Compute 15 * 7.'}\n",
      "\n",
      "--- EVAL split ---\n",
      "{'single_turn_completion': 'Paris.',\n",
      " 'single_turn_metadata': {'difficulty': 'easy'},\n",
      " 'single_turn_prompt': 'What is the capital of France?'}\n",
      "\n",
      "First entry via __getitem__:\n",
      "{'prompt': 'What is the capital of France?', 'completion': 'Paris.', 'difficulty': 'easy'}\n",
      "\n",
      "Total entries: 5\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------ #\n",
    "# 3) Convert to HuggingFace DatasetDict                  #\n",
    "# ------------------------------------------------------ #\n",
    "hf_datasets: DatasetDict = dataset.to_hf_dataset()\n",
    "print(\"Dataset splits:\", hf_datasets)\n",
    "\n",
    "# ------------------------------------------------------ #\n",
    "# 4) Inspect split sizes                                #\n",
    "# ------------------------------------------------------ #\n",
    "splits_info = dataset.get_splits_info()\n",
    "print(\"Split info:\", splits_info)\n",
    "\n",
    "# ------------------------------------------------------ #\n",
    "# 5) Peek at one example from each split                 #\n",
    "# ------------------------------------------------------ #\n",
    "for split_name, split_ds in hf_datasets.items():\n",
    "    print(f\"\\n--- {split_name.upper()} split ---\")\n",
    "    # Each row has: single_turn_prompt, single_turn_completion, metadata\n",
    "    row0 = split_ds[0]\n",
    "    pprint(row0)\n",
    "\n",
    "# ------------------------------------------------------ #\n",
    "# 6) Accessing entries via __getitem__                   #\n",
    "# ------------------------------------------------------ #\n",
    "print(\"\\nFirst entry via __getitem__:\")\n",
    "print(dataset[0])\n",
    "\n",
    "print(\"\\nTotal entries:\", len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiturn dataset\n",
    "\n",
    "There are two ways to create a multiturn dataset:\n",
    "- Provide a list of data entries (by separated rows or nested dictionary).\n",
    "- Specifify a huggingface dataset repo name ([example format](https://huggingface.co/datasets/collabllm/collabllm-multiturn-math-hard)) or a local directory containing a huggingface dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1.1: Create a multiturn dataset from a list of data entries (separated rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 14:03:15,446 [INFO] collabllm.datasets.multiturn: Converted 3 dialogues (filter: None ≥ 0.0); retention ratio: 1.00\n",
      "2025-06-13 14:03:15,460 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=3 (turn_id=1) due to score=0.500 < 0.600\n",
      "2025-06-13 14:03:15,461 [INFO] collabllm.datasets.multiturn: Converted 2 dialogues (filter: score ≥ 0.6); retention ratio: 0.67\n",
      "2025-06-13 14:03:15,474 [INFO] collabllm.datasets.multiturn: Converted 2 pairs (minimum_gap=0.2, ratio=0.33)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SFT:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['messages'],\n",
      "        num_rows: 3\n",
      "    })\n",
      "    eval: Dataset({\n",
      "        features: ['messages'],\n",
      "        num_rows: 0\n",
      "    })\n",
      "})\n",
      "{'messages': [{'content': 'Hi – tell me a joke.', 'role': 'user'},\n",
      "              {'content': 'Why did the chicken cross the road? To get to the '\n",
      "                          'other side!',\n",
      "               'role': 'assistant'},\n",
      "              {'content': 'And another one?', 'role': 'user'},\n",
      "              {'content': 'What do you call a bear with no teeth? A gummy '\n",
      "                          'bear!',\n",
      "               'role': 'assistant'}]}\n",
      "\n",
      "SFT (lower bound=0.6):\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['messages'],\n",
      "        num_rows: 2\n",
      "    })\n",
      "    eval: Dataset({\n",
      "        features: ['messages'],\n",
      "        num_rows: 0\n",
      "    })\n",
      "})\n",
      "{'messages': [{'content': 'Hi – tell me a joke.', 'role': 'user'},\n",
      "              {'content': 'Why did the chicken cross the road? To get to the '\n",
      "                          'other side!',\n",
      "               'role': 'assistant'},\n",
      "              {'content': 'And another one?', 'role': 'user'},\n",
      "              {'content': 'What do you call a bear with no teeth? A gummy '\n",
      "                          'bear!',\n",
      "               'role': 'assistant'}]}\n",
      "\n",
      "DPO:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['prompt', 'chosen', 'rejected', 'score_chosen', 'score_rejected'],\n",
      "        num_rows: 2\n",
      "    })\n",
      "    eval: Dataset({\n",
      "        features: ['prompt', 'chosen', 'rejected', 'score_chosen', 'score_rejected'],\n",
      "        num_rows: 0\n",
      "    })\n",
      "})\n",
      "{'chosen': 'Why did the chicken cross the road? To get to the other side!',\n",
      " 'prompt': [{'content': 'Hi – tell me a joke.', 'role': 'user'}],\n",
      " 'rejected': \"I don't know any jokes.\",\n",
      " 'score_chosen': 0.7,\n",
      " 'score_rejected': 0.1}\n",
      "\n",
      "Inputs:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['prompt', 'single_turn_prompt', 'single_turn_completion', 'single_turn_metadata'],\n",
      "        num_rows: 4\n",
      "    })\n",
      "    eval: Dataset({\n",
      "        features: ['prompt', 'single_turn_prompt', 'single_turn_completion', 'single_turn_metadata'],\n",
      "        num_rows: 0\n",
      "    })\n",
      "})\n",
      "{'prompt': [{'content': 'Hi – tell me a joke.', 'role': 'user'}],\n",
      " 'single_turn_completion': 'Why did the chicken cross the road?',\n",
      " 'single_turn_metadata': {'topic': 'jokes'},\n",
      " 'single_turn_prompt': 'Tell me a joke.'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from datasets import Dataset, DatasetDict\n",
    "from collabllm.datasets import MultiturnDataset\n",
    "\n",
    "# ------------------------------------------------------ #\n",
    "# 1) Toy corpus: three conversations, four rows total    #\n",
    "# ------------------------------------------------------ #\n",
    "toy_data = [\n",
    "    {  # convo A, turn 2 (higher score)\n",
    "        \"prompt\": [\n",
    "            {\"role\": \"user\", \"content\": \"Hi – tell me a joke.\"},\n",
    "        ],\n",
    "        \"completion\": \"Why did the chicken cross the road? To get to the other side!\",\n",
    "        \"conv_id\": 1,\n",
    "        \"score\": 0.7,\n",
    "        \"single_turn_prompt\": \"Tell me a joke.\",\n",
    "        \"single_turn_completion\": \"Why did the chicken cross the road?\",\n",
    "        \"single_turn_metadata\": {\"topic\": \"jokes\"},\n",
    "    },\n",
    "    {  # convo A, turn 2 (lower score)\n",
    "        \"prompt\": [\n",
    "            {\"role\": \"user\", \"content\": \"Hi – tell me a joke.\"},\n",
    "        ],\n",
    "        \"completion\": \"I don't know any jokes.\",\n",
    "        \"conv_id\": 1,\n",
    "        \"score\": 0.1,\n",
    "        \"single_turn_prompt\": \"Tell me a joke.\",\n",
    "        \"single_turn_completion\": \"I don't know any jokes.\",\n",
    "        \"single_turn_metadata\": {\"topic\": \"jokes\"},\n",
    "    },\n",
    "    {  # convo A, turn 4 (higher score)\n",
    "        \"prompt\": [\n",
    "            {\"role\": \"user\", \"content\": \"Hi – tell me a joke.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Why did the chicken cross the road? To get to the other side!\"}, # the same as turn 2 (higher score)\n",
    "            {\"role\": \"user\", \"content\": \"And another one?\"},\n",
    "        ],\n",
    "        \"completion\": \"What do you call a bear with no teeth? A gummy bear!\",\n",
    "        \"conv_id\": 1,\n",
    "        \"score\": 0.8,\n",
    "        \"single_turn_prompt\": \"Tell me a joke.\",\n",
    "        \"single_turn_completion\": \"I don't know any jokes.\",\n",
    "        \"single_turn_metadata\": {\"topic\": \"jokes\"},\n",
    "    },\n",
    "    {  # convo A, turn 4 (lower score)\n",
    "        \"prompt\": [\n",
    "            {\"role\": \"user\", \"content\": \"Hi – tell me a joke.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Why did the chicken cross the road? To get to the other side!\"},\n",
    "            {\"role\": \"user\", \"content\": \"And another one?\"},\n",
    "        ],\n",
    "        \"completion\": \"I don't know any jokes.\",\n",
    "        \"conv_id\": 1,\n",
    "        \"score\": 0.1,\n",
    "        \"single_turn_prompt\": \"Tell me a joke.\",\n",
    "        \"single_turn_completion\": \"I don't know any jokes.\",\n",
    "        \"single_turn_metadata\": {\"topic\": \"jokes\"},\n",
    "    },\n",
    "    {  # convo B, turn 4\n",
    "        \"prompt\": [\n",
    "            {\"role\": \"user\", \"content\": \"Sum 2+2\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"4\"},\n",
    "            {\"role\": \"user\", \"content\": \"And 3+3?\"},\n",
    "        ],\n",
    "        \"completion\": \"6\",\n",
    "        \"conv_id\": 2,\n",
    "        \"score\": 0.9,\n",
    "        \"single_turn_prompt\": \"What is 3+3?\",\n",
    "        \"single_turn_completion\": \"6\",\n",
    "        \"single_turn_metadata\": {\"topic\": \"math\"},\n",
    "    },\n",
    "    {  # convo C, turn 2\n",
    "        \"prompt\": [{\"role\": \"user\", \"content\": \"Quote Shakespeare\"}],\n",
    "        \"completion\": \"To be, or not to be.\",\n",
    "        \"conv_id\": 3,\n",
    "        \"score\": 0.5,\n",
    "        \"single_turn_prompt\": \"Quote Shakespeare\",\n",
    "        \"single_turn_completion\": \"To be, or not to be.\",\n",
    "        \"single_turn_metadata\": {\"topic\": \"literature\"},\n",
    "    },\n",
    "]\n",
    "\n",
    "# Add system prompt (by default)\n",
    "# ds = MultiturnDataset(toy_data, seed=42)\n",
    "\n",
    "ds = MultiturnDataset(toy_data, seed=42, add_system_prompt=False)\n",
    "\n",
    "# ------------------------------------------------------ #\n",
    "# 2) SFT                                                 #\n",
    "# ------------------------------------------------------ #\n",
    "sft = ds.to_sft_dataset()\n",
    "print(\"\\nSFT:\")\n",
    "print(sft)\n",
    "pprint(sft[\"train\"][0])\n",
    "\n",
    "# You can filter out conversations where the `lower_bound_metric` at the last turn is below `lower_bound`.\n",
    "sft = ds.to_sft_dataset(lower_bound_metric=\"score\", lower_bound=0.6)\n",
    "print(\"\\nSFT (lower bound=0.6):\")\n",
    "print(sft)\n",
    "pprint(sft[\"train\"][0])\n",
    "\n",
    "# ------------------------------------------------------ #\n",
    "# 3) DPO (gap filter 0.2)                                #\n",
    "# ------------------------------------------------------ #\n",
    "# You can convert to DPO dataset, which will filter out conversations where scores between chosen and rejected completions are lower than `minimum_gap`\n",
    "dpo = ds.to_dpo_dataset(minimum_gap=0.2)\n",
    "print(\"\\nDPO:\")\n",
    "print(dpo)\n",
    "if len(dpo[\"train\"]) > 0:\n",
    "    pprint(dpo[\"train\"][0])\n",
    "\n",
    "# ------------------------------------------------------ #\n",
    "# 4) Inputs                                              #\n",
    "# ------------------------------------------------------ #\n",
    "inputs = ds.to_inputs_dataset()\n",
    "print(\"\\nInputs:\")\n",
    "print(inputs)\n",
    "pprint(inputs[\"train\"][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1.2: Create a multiturn dataset from a list of data entries (nested dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 14:03:15,590 [INFO] collabllm.datasets.multiturn: Converted 2 dialogues (filter: None ≥ 0.0); retention ratio: 1.00\n",
      "2025-06-13 14:03:15,603 [INFO] collabllm.datasets.multiturn: Converted 1 pairs (minimum_gap=0.3, ratio=0.25)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SFT from nested data ===\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['messages'],\n",
      "        num_rows: 2\n",
      "    })\n",
      "    eval: Dataset({\n",
      "        features: ['messages'],\n",
      "        num_rows: 0\n",
      "    })\n",
      "})\n",
      "{'messages': [{'content': 'Another one?', 'role': 'user'},\n",
      "              {'content': 'Why did the chicken cross the road? To get to the '\n",
      "                          'other side!',\n",
      "               'role': 'assistant'},\n",
      "              {'content': 'Yes, another.', 'role': 'user'},\n",
      "              {'content': 'What do you call a bear with no teeth? A gummy '\n",
      "                          'bear!',\n",
      "               'role': 'assistant'}]}\n",
      "\n",
      "=== DPO from nested data ===\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['prompt', 'chosen', 'rejected', 'score_chosen', 'score_rejected'],\n",
      "        num_rows: 1\n",
      "    })\n",
      "    eval: Dataset({\n",
      "        features: ['prompt', 'chosen', 'rejected', 'score_chosen', 'score_rejected'],\n",
      "        num_rows: 0\n",
      "    })\n",
      "})\n",
      "{'chosen': 'Why did the chicken cross the road? To get to the other side!',\n",
      " 'prompt': [{'content': 'Hi, tell me a joke.', 'role': 'user'}],\n",
      " 'rejected': 'I don’t know any jokes.',\n",
      " 'score_chosen': 0.7,\n",
      " 'score_rejected': 0.2}\n",
      "\n",
      "=== Inputs from nested data ===\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['prompt', 'single_turn_prompt', 'single_turn_completion', 'single_turn_metadata'],\n",
      "        num_rows: 3\n",
      "    })\n",
      "    eval: Dataset({\n",
      "        features: ['prompt', 'single_turn_prompt', 'single_turn_completion', 'single_turn_metadata'],\n",
      "        num_rows: 0\n",
      "    })\n",
      "})\n",
      "{'prompt': [{'content': 'Hi, tell me a joke.', 'role': 'user'}],\n",
      " 'single_turn_completion': 'Why did the chicken cross the road?',\n",
      " 'single_turn_metadata': {'category': 'humor'},\n",
      " 'single_turn_prompt': 'Tell me a joke.'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from datasets import DatasetDict\n",
    "from collabllm.datasets import MultiturnDataset\n",
    "\n",
    "# ------------------------------------------------------ #\n",
    "# 1) Example with nested input format                    #\n",
    "# ------------------------------------------------------ #\n",
    "nested_data = [\n",
    "    {\n",
    "        \"single_turn_prompt\": \"Tell me a joke.\",\n",
    "        \"single_turn_completion\": \"Why did the chicken cross the road?\",\n",
    "        \"single_turn_metadata\": {\"category\": \"humor\"},\n",
    "        \"turns\": [\n",
    "            {\n",
    "                \"prompt\": [{\"role\": \"user\", \"content\": \"Hi, tell me a joke.\"}],\n",
    "                \"responses\": [\n",
    "                    {\"completion\": \"Why did the chicken cross the road? To get to the other side!\", \"score\": 0.7},\n",
    "                    {\"completion\": \"I don’t know any jokes.\", \"score\": 0.2},\n",
    "                ],\n",
    "            },\n",
    "            {\n",
    "                \"prompt\": [\n",
    "                    {\"role\": \"user\", \"content\": \"Another one?\"},\n",
    "                    {\"role\": \"assistant\", \"content\": \"Why did the chicken cross the road? To get to the other side!\"},\n",
    "                    {\"role\": \"user\", \"content\": \"Yes, another.\"},\n",
    "                ],\n",
    "                \"responses\": [\n",
    "                    {\"completion\": \"What do you call a bear with no teeth? A gummy bear!\", \"score\": 0.8},\n",
    "                ],\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"single_turn_prompt\": \"Sum 2+2.\",\n",
    "        \"single_turn_completion\": \"2+2=4\",\n",
    "        \"single_turn_metadata\": {\"category\": \"math\"},\n",
    "        \"turns\": [\n",
    "            {\n",
    "                \"prompt\": [{\"role\": \"user\", \"content\": \"Sum 2+2\"}],\n",
    "                \"responses\": [\n",
    "                    {\"completion\": \"4\", \"score\": 0.9},\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "ds_nested = MultiturnDataset(nested_data, seed=123, add_system_prompt=False)\n",
    "\n",
    "# Add system prompt (by default)\n",
    "# ds_nested = MultiturnDataset(nested_data, seed=123, add_system_prompt=True)\n",
    "\n",
    "print(\"=== SFT from nested data ===\")\n",
    "sft_ds: DatasetDict = ds_nested.to_sft_dataset()\n",
    "print(sft_ds)\n",
    "pprint(sft_ds[\"train\"][0])  # one example from train split\n",
    "\n",
    "print(\"\\n=== DPO from nested data ===\")\n",
    "dpo_ds: DatasetDict = ds_nested.to_dpo_dataset(minimum_gap=0.3)\n",
    "print(dpo_ds)\n",
    "if len(dpo_ds[\"train\"]) > 0:\n",
    "    pprint(dpo_ds[\"train\"][0])\n",
    "\n",
    "print(\"\\n=== Inputs from nested data ===\")\n",
    "inputs_ds: DatasetDict = ds_nested.to_inputs_dataset()\n",
    "print(inputs_ds)\n",
    "pprint(inputs_ds[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2.1: Create a multiturn dataset from huggingface dataset repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e886a0f2819247da9d02127c82e75af3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.04k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1003ef7a6b014c87be4b06ecf8ef5673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/1.30M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2115b3b8cba4c43b69a1f3cd6e457be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/372 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 14:03:19,117 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=11 (turn_id=9) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-06-13 14:03:19,118 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=15 (turn_id=5) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-06-13 14:03:19,118 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=17 (turn_id=13) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-06-13 14:03:19,118 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=18 (turn_id=5) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-06-13 14:03:19,119 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=19 (turn_id=7) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-06-13 14:03:19,119 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=29 (turn_id=13) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-06-13 14:03:19,119 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=32 (turn_id=5) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-06-13 14:03:19,120 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=39 (turn_id=1) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-06-13 14:03:19,120 [INFO] collabllm.datasets.multiturn: Converted 32 dialogues (filter: rewards.accuracy ≥ 0.5); retention ratio: 0.80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SFT ===\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['messages'],\n",
      "        num_rows: 29\n",
      "    })\n",
      "    eval: Dataset({\n",
      "        features: ['messages'],\n",
      "        num_rows: 3\n",
      "    })\n",
      "})\n",
      "{'messages': [{'content': 'The assistant is designed to be helpful, proactive, and highly interactive.\\n\\nThe assistant strives to accurately interpret the user\\'s intent throughout the conversation, acknowledging previous interactions to maintain context and continuity. If the user\\'s message is unclear or lacks necessary details, the assistant always asks for clarification rather than making assumptions. For example, if the user\\'s request is incomplete, the assistant responds with: \"Could you provide more details so I can assist you better?\"\\n\\nThe assistant asks specific follow-up questions and offers suggestions based on the user\\'s needs, avoiding vague or generic prompts. It proactively provides guidance and potential next steps, especially in complex tasks such as writing, analysis, coding, and question answering.\\n\\nThe assistant is mindful of how much content the user needs to read or type, keeping interactions concise and efficient. It reduces unnecessary repetition and ensures responses are relevant, well-structured, and free from errors. When presenting options or asking for feedback, the assistant simplifies interactions by offering multiple-choice answers or specific suggestions to make it easier for the user to respond quickly.\\n\\nThe assistant adapts its tone to align with the user\\'s emotional state and style, adjusting its approach as needed. If uncertain about something, the assistant honestly says, \"I don\\'t know,\" and suggests ways for the user to find the information.\\n\\nThe assistant provides factually accurate, coherent, and relevant responses, using proper grammar and structure. It remains interactive and proactive across all tasks, continually seeking feedback to refine and improve interactions.', 'role': 'system'}, {'content': \"Hey, I'm trying to solve a problem involving two infinite geometric series. The first series has a first term of 12 and a second term of 4. The second series has the same first term of 12, but its second term is 4+n, and the sum is four times that of the first series. Any ideas on how to find the value of n?\", 'role': 'user'}, {'content': 'To solve this problem, we need to analyze the given geometric series. \\n\\n### First Series\\nThe first term \\\\( a_1 \\\\) of the first series is 12, and the second term is 4. In a geometric series, the second term is given by \\\\( a_1 \\\\cdot r_1 \\\\), where \\\\( r_1 \\\\) is the common ratio. Therefore, we have:\\n\\\\[\\n12 \\\\cdot r_1 = 4\\n\\\\]\\nSolving for \\\\( r_1 \\\\), we get:\\n\\\\[\\nr_1 = \\\\frac{4}{12} = \\\\frac{1}{3}\\n\\\\]\\n\\nThe sum \\\\( S_1 \\\\) of the first infinite geometric series is given by:\\n\\\\[\\nS_1 = \\\\frac{a_1}{1 - r_1} = \\\\frac{12}{1 - \\\\frac{1}{3}} = \\\\frac{12}{\\\\frac{2}{3}} = 18\\n\\\\]\\n\\n### Second Series\\nThe second series has the same first term, 12, and a second term of \\\\( 4 + n \\\\). This second term is equal to \\\\( 12 \\\\cdot r_2 \\\\), where \\\\( r_2 \\\\) is the common ratio for the second series:\\n\\\\[\\n12 \\\\cdot r_2 = 4 + n\\n\\\\]\\nSolving for \\\\( r_2 \\\\), we get:\\n\\\\[\\nr_2 = \\\\frac{4 + n}{12}\\n\\\\]\\n\\nThe sum \\\\( S_2 \\\\) of the second infinite geometric series is given by:\\n\\\\[\\nS_2 = \\\\frac{a_1}{1 - r_2} = \\\\frac{12}{1 - \\\\frac{4+n}{12}} = \\\\frac{12}{\\\\frac{12 - 4 - n}{12}} = \\\\frac{12 \\\\cdot 12}{8 - n}\\n\\\\]\\n\\n### Relationship Between Series\\nWe are told that the sum of the second series is four times the sum of the first series:\\n\\\\[\\nS_2 = 4 \\\\cdot S_1\\n\\\\]\\n\\\\[\\n\\\\frac{144}{8 - n} = 4 \\\\times 18\\n\\\\]\\n\\\\[\\n\\\\frac{144}{8 - n} = 72\\n\\\\]\\n\\nNow, solve for \\\\( n \\\\):\\n\\\\[\\n144 = 72 \\\\times (8 - n)\\n\\\\]\\n\\\\[\\n144 = 576 - 72n\\n\\\\]\\n\\\\[\\n72n = 576 - 144\\n\\\\]\\n\\\\[\\n72n = 432\\n\\\\]\\n\\\\[\\nn = \\\\frac{432}{72} = 6\\n\\\\]\\n\\nThus, the value of \\\\( n \\\\) is \\\\( \\\\boxed{6} \\\\).', 'role': 'assistant'}]}\n"
     ]
    }
   ],
   "source": [
    "from collabllm.datasets import MultiturnDataset\n",
    "\n",
    "ds = MultiturnDataset('collabllm/collabllm-multiturn-math-hard', add_system_prompt=True)\n",
    "\n",
    "print(\"=== SFT ===\")\n",
    "sft_ds: DatasetDict = ds.to_sft_dataset(eval_ratio=0.1, lower_bound_metric=\"rewards.accuracy\", lower_bound=0.5)\n",
    "print(sft_ds)\n",
    "print(sft_ds[\"train\"][0])  # one example from train split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When specify DPO dataset, set `minimum_gap` to filter out pairs where the score difference is below `minimum_gap`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 13:27:50,804 [INFO] collabllm.datasets.multiturn: Converted 824 pairs (minimum_gap=0.1, ratio=0.12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 13:27:50,846 [INFO] collabllm.datasets.multiturn: Converted 392 pairs (minimum_gap=0.2, ratio=0.06)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DPO (minimum gap = 0.1) ===\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['prompt', 'chosen', 'rejected', 'score_chosen', 'score_rejected'],\n",
      "        num_rows: 742\n",
      "    })\n",
      "    eval: Dataset({\n",
      "        features: ['prompt', 'chosen', 'rejected', 'score_chosen', 'score_rejected'],\n",
      "        num_rows: 82\n",
      "    })\n",
      "})\n",
      "\n",
      "=== DPO (minimum gap = 0.2) ===\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['prompt', 'chosen', 'rejected', 'score_chosen', 'score_rejected'],\n",
      "        num_rows: 353\n",
      "    })\n",
      "    eval: Dataset({\n",
      "        features: ['prompt', 'chosen', 'rejected', 'score_chosen', 'score_rejected'],\n",
      "        num_rows: 39\n",
      "    })\n",
      "})\n",
      "{'prompt': [{'content': 'The assistant is designed to be helpful, proactive, and highly interactive.\\n\\nThe assistant strives to accurately interpret the user\\'s intent throughout the conversation, acknowledging previous interactions to maintain context and continuity. If the user\\'s message is unclear or lacks necessary details, the assistant always asks for clarification rather than making assumptions. For example, if the user\\'s request is incomplete, the assistant responds with: \"Could you provide more details so I can assist you better?\"\\n\\nThe assistant asks specific follow-up questions and offers suggestions based on the user\\'s needs, avoiding vague or generic prompts. It proactively provides guidance and potential next steps, especially in complex tasks such as writing, analysis, coding, and question answering.\\n\\nThe assistant is mindful of how much content the user needs to read or type, keeping interactions concise and efficient. It reduces unnecessary repetition and ensures responses are relevant, well-structured, and free from errors. When presenting options or asking for feedback, the assistant simplifies interactions by offering multiple-choice answers or specific suggestions to make it easier for the user to respond quickly.\\n\\nThe assistant adapts its tone to align with the user\\'s emotional state and style, adjusting its approach as needed. If uncertain about something, the assistant honestly says, \"I don\\'t know,\" and suggests ways for the user to find the information.\\n\\nThe assistant provides factually accurate, coherent, and relevant responses, using proper grammar and structure. It remains interactive and proactive across all tasks, continually seeking feedback to refine and improve interactions.', 'role': 'system'}, {'content': 'Can you rewrite the article to focus more on the wallpapers—their quality, how they look on different devices, and why someone should download them? Also, keep it under 500 words but less technical about the car itself or maintenance stuff.', 'role': 'user'}], 'chosen': \"I'd be happy to help with rewriting the article to focus more on the wallpapers. To tailor the rewrite to your needs, could you provide more details about the original article? For example, what type of wallpapers are being discussed, and is there a specific feature or aspect you'd like to emphasize? Understanding these details will help ensure the rewrite aligns with your vision. Additionally, would you like me to include any specific points regarding the wallpapers' visual appeal or compatibility with different devices?\", 'rejected': \"Certainly! Here's a revised version focusing on the wallpapers:\\n\\n---\\n\\n**Enhance Your Screen with Stunning Car Wallpapers**\\n\\nIn the digital age, personalizing your devices is more than just a trend; it's a way to express your unique style and interests. For car enthusiasts and admirers of sleek design, high-quality car wallpapers provide the perfect opportunity to bring the allure of automotive excellence to your screen. These wallpapers not only enhance the aesthetic appeal of your devices but also serve as a daily reminder of the beauty and innovation that the automotive world has to offer.\\n\\n**Unmatched Quality and Detail**\\n\\nThe car wallpapers available today are crafted with precision and attention to detail, ensuring that every curve and contour of the vehicle is captured in stunning clarity. High-resolution images make these wallpapers suitable for a variety of devices, from the latest smartphones and tablets to expansive desktop monitors. The sharpness and vibrant colors bring the vehicles to life, allowing you to appreciate every nuance of their design.\\n\\n**Versatility Across Devices**\\n\\nOne of the remarkable features of these wallpapers is their versatility. Whether you're using a small smartphone screen or a large desktop monitor, these images adapt beautifully to different resolutions and aspect ratios. This adaptability ensures that the quality remains consistently high, regardless of the device. The seamless fit and crisp details make these wallpapers a delightful addition to any screen, providing a luxurious and polished look.\\n\\n**Why Download Car Wallpapers?**\\n\\nChoosing a car wallpaper is not just about aesthetics; it's about making a statement. Here are a few reasons why you should consider downloading these stunning images:\\n\\n1. **Personal Expression**: Show off your passion for cars by bringing your favorite models to your screens. Whether you're a fan of classic muscle cars or modern electric vehicles, there's a wallpaper that perfectly captures your interest.\\n\\n2. **Inspiration and Motivation**: Having an inspiring car wallpaper on your device can serve as a daily motivator. The sleek lines and powerful presence of these cars remind you of the innovation and excellence they represent.\\n\\n3. **Visual Appeal**: A high-quality wallpaper dramatically enhances the look of your device. The vivid imagery and dynamic composition turn an ordinary screen into a visual masterpiece.\\n\\n4. **Conversation Starter**: Unique and eye-catching wallpapers can spark conversations with friends and colleagues who share your automotive passion or are simply intrigued by your choice of wallpaper.\\n\\n**Easy Access and Variety**\\n\\nAccessing these stunning car wallpapers is easier than ever. A wide array of websites and apps offer an extensive collection of images featuring various car models and styles. Whether you prefer a classic look or a modern aesthetic, the options are virtually endless. With just a few clicks, you can download and apply your favorite images, transforming your device instantly.\\n\\nIn conclusion, car wallpapers offer a perfect blend of style, quality, and personalization. They not only enhance the visual appeal of your devices but also reflect your passion for automotive design. Upgrade your screens today with these stunning images and let your devices shine with the elegance and power of the automotive world.\", 'score_chosen': 1.111595897773021, 'score_rejected': 0.8476926120901468}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== DPO (minimum gap = 0.1) ===\")\n",
    "dpo_ds: DatasetDict = ds.to_dpo_dataset(minimum_gap=0.1, eval_ratio=0.1)\n",
    "print(dpo_ds)\n",
    "\n",
    "print(\"\\n=== DPO (minimum gap = 0.2) ===\")\n",
    "dpo_ds: DatasetDict = ds.to_dpo_dataset(minimum_gap=0.2, eval_ratio=0.1)\n",
    "print(dpo_ds.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Inputs ===\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['prompt', 'single_turn_prompt', 'single_turn_completion', 'single_turn_metadata'],\n",
      "        num_rows: 3018\n",
      "    })\n",
      "    eval: Dataset({\n",
      "        features: ['prompt', 'single_turn_prompt', 'single_turn_completion', 'single_turn_metadata'],\n",
      "        num_rows: 335\n",
      "    })\n",
      "})\n",
      "{'prompt': [{'content': 'The assistant is designed to be helpful, proactive, and highly interactive.\\n\\nThe assistant strives to accurately interpret the user\\'s intent throughout the conversation, acknowledging previous interactions to maintain context and continuity. If the user\\'s message is unclear or lacks necessary details, the assistant always asks for clarification rather than making assumptions. For example, if the user\\'s request is incomplete, the assistant responds with: \"Could you provide more details so I can assist you better?\"\\n\\nThe assistant asks specific follow-up questions and offers suggestions based on the user\\'s needs, avoiding vague or generic prompts. It proactively provides guidance and potential next steps, especially in complex tasks such as writing, analysis, coding, and question answering.\\n\\nThe assistant is mindful of how much content the user needs to read or type, keeping interactions concise and efficient. It reduces unnecessary repetition and ensures responses are relevant, well-structured, and free from errors. When presenting options or asking for feedback, the assistant simplifies interactions by offering multiple-choice answers or specific suggestions to make it easier for the user to respond quickly.\\n\\nThe assistant adapts its tone to align with the user\\'s emotional state and style, adjusting its approach as needed. If uncertain about something, the assistant honestly says, \"I don\\'t know,\" and suggests ways for the user to find the information.\\n\\nThe assistant provides factually accurate, coherent, and relevant responses, using proper grammar and structure. It remains interactive and proactive across all tasks, continually seeking feedback to refine and improve interactions.', 'role': 'system'}, {'content': 'Can you rewrite the article to focus more on the wallpapers—their quality, how they look on different devices, and why someone should download them? Also, keep it under 500 words but less technical about the car itself or maintenance stuff.', 'role': 'user'}], 'single_turn_prompt': 'Please write an article in less than 500 words about:\\n\\nDownload luxury Nissan GTR Wallpaper for your desktop and mobile screens. These high-resolution images will make your day\\n\\nDownload luxury Nissan GTR Wallpaper for your desktop and mobile screens. These high-resolution images will make your day Harmony True Dec 28, 2021·1 min read\\n\\nNissan is a Japanese automobile manufacturer founded in 1933. The company has introduced a total of six generations of GTR, all of which have become a success in the racing world.\\n\\nhttps://www.4wall.site/2021/12/download-nissan-gtr-wallpaper-4k-and.html\\n\\nNissan GTR Wallpaper\\n\\nDownload Nissan GTR Wallpaper for Free.\\n\\nIt’s time to show off your GTR with the best Nissan GTR wallpaper. These high quality wallpapers will make you feel like you’re driving the car of your dreams every day.\\n\\nI’m a proud owner of a Nissan GTR and I wanted to share my experience with you. It’s a really beautiful car, but it requires a lot of maintenance. My mechanic advised me to install a tire pressure monitoring system. This way I know when one of the tires is about to lose air pressure. It could be because of a puncture or simply because the tire pressure has lowered over time.', 'single_turn_completion': 'Download luxury Nissan GTR Wallpaper for your desktop and mobile screens. These high-resolution images will make your day Harmony True Dec 28, 2021·1 min read\\n\\nNissan is a Japanese automobile manufacturer founded in 1933. The company has introduced a total of six generations of GTR, all of which have become a success in the racing world.\\n\\nhttps://www.4wall.site/2021/12/download-nissan-gtr-wallpaper-4k-and.html\\n\\nNissan GTR Wallpaper\\n\\nDownload Nissan GTR Wallpaper for Free.\\n\\nIt’s time to show off your GTR with the best Nissan GTR wallpaper. These high quality wallpapers will make you feel like you’re driving the car of your dreams every day.\\n\\nI’m a proud owner of a Nissan GTR and I wanted to share my experience with you. It’s a really beautiful car, but it requires a lot of maintenance. My mechanic advised me to install a tire pressure monitoring system. This way I know when one of the tires is about to lose air pressure. It could be because of a puncture or simply because the tire pressure has lowered over time.', 'single_turn_metadata': {'authors': \"['Harmony True']\", 'num_tokens': 231, 'tags': \"['Download', 'Wallpaper', 'Nissangtr', 'Nissan Cars', 'Nissan']\", 'timestamp': '2021-12-28 00:50:49.726000+00:00', 'url': 'https://medium.com/@trueharmony670/download-luxury-nissan-gtr-wallpaper-for-your-desktop-and-mobile-screens-81e505deba1e'}}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Inputs ===\")\n",
    "inputs_ds: DatasetDict = ds.to_inputs_dataset(eval_ratio=0.1)\n",
    "print(inputs_ds)\n",
    "print(inputs_ds[\"train\"][0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2.2: Create a multiturn dataset from a local directory\n",
    "\n",
    "You can load the dataset from a local directory which is saved by `ds.save_to_disk` where ds is a HuggingFace Dataset object."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "collabllm-beta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
